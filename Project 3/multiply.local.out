Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/10/25 12:50:59 INFO SparkContext: Running Spark version 1.5.2
17/10/25 12:51:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 12:51:00 INFO SecurityManager: Changing view acls to: sattri
17/10/25 12:51:00 INFO SecurityManager: Changing modify acls to: sattri
17/10/25 12:51:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sattri); users with modify permissions: Set(sattri)
17/10/25 12:51:01 INFO Slf4jLogger: Slf4jLogger started
17/10/25 12:51:01 INFO Remoting: Starting remoting
17/10/25 12:51:01 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@198.202.114.117:33421]
17/10/25 12:51:01 INFO Utils: Successfully started service 'sparkDriver' on port 33421.
17/10/25 12:51:01 INFO SparkEnv: Registering MapOutputTracker
17/10/25 12:51:01 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 12:51:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e2d04ec8-e5f1-4d06-aeee-e036370f1a21
17/10/25 12:51:01 INFO MemoryStore: MemoryStore started with capacity 530.0 MB
17/10/25 12:51:01 INFO HttpFileServer: HTTP File server directory is /tmp/spark-f725472b-5f4a-4f30-83f9-45430b84dd5b/httpd-1c826890-2b6a-401b-acc3-b09642f2e983
17/10/25 12:51:01 INFO HttpServer: Starting HTTP Server
17/10/25 12:51:02 INFO Utils: Successfully started service 'HTTP file server' on port 41193.
17/10/25 12:51:02 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 12:51:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/25 12:51:02 INFO SparkUI: Started SparkUI at http://198.202.114.117:4040
17/10/25 12:51:02 INFO SparkContext: Added JAR file:/home/sattri/project3/multiply.jar at http://198.202.114.117:41193/jars/multiply.jar with timestamp 1508961062540
17/10/25 12:51:02 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.
17/10/25 12:51:02 INFO Executor: Starting executor ID driver on host localhost
17/10/25 12:51:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39878.
17/10/25 12:51:02 INFO NettyBlockTransferService: Server created on 39878
17/10/25 12:51:02 INFO BlockManagerMaster: Trying to register BlockManager
17/10/25 12:51:02 INFO BlockManagerMasterEndpoint: Registering block manager localhost:39878 with 530.0 MB RAM, BlockManagerId(driver, localhost, 39878)
17/10/25 12:51:02 INFO BlockManagerMaster: Registered BlockManager
17/10/25 12:51:04 INFO MemoryStore: ensureFreeSpace(120040) called with curMem=0, maxMem=555755765
17/10/25 12:51:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 117.2 KB, free 529.9 MB)
17/10/25 12:51:04 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=120040, maxMem=555755765
17/10/25 12:51:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.9 MB)
17/10/25 12:51:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:39878 (size: 12.4 KB, free: 530.0 MB)
17/10/25 12:51:04 INFO SparkContext: Created broadcast 0 from textFile at Multiply.scala:23
17/10/25 12:51:04 INFO MemoryStore: ensureFreeSpace(120080) called with curMem=132713, maxMem=555755765
17/10/25 12:51:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 117.3 KB, free 529.8 MB)
17/10/25 12:51:04 INFO MemoryStore: ensureFreeSpace(12673) called with curMem=252793, maxMem=555755765
17/10/25 12:51:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 12.4 KB, free 529.8 MB)
17/10/25 12:51:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:39878 (size: 12.4 KB, free: 530.0 MB)
17/10/25 12:51:04 INFO SparkContext: Created broadcast 1 from textFile at Multiply.scala:26
17/10/25 12:51:04 INFO FileInputFormat: Total input paths to process : 1
17/10/25 12:51:04 INFO FileInputFormat: Total input paths to process : 1
17/10/25 12:51:04 INFO SparkContext: Starting job: collect at Multiply.scala:33
17/10/25 12:51:04 INFO DAGScheduler: Registering RDD 7 (map at Multiply.scala:29)
17/10/25 12:51:05 INFO DAGScheduler: Registering RDD 6 (map at Multiply.scala:28)
17/10/25 12:51:05 INFO DAGScheduler: Registering RDD 11 (map at Multiply.scala:30)
17/10/25 12:51:05 INFO DAGScheduler: Got job 0 (collect at Multiply.scala:33) with 2 output partitions
17/10/25 12:51:05 INFO DAGScheduler: Final stage: ResultStage 3(collect at Multiply.scala:33)
17/10/25 12:51:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/10/25 12:51:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/10/25 12:51:05 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at map at Multiply.scala:29), which has no missing parents
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(3728) called with curMem=265466, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.6 KB, free 529.8 MB)
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(2166) called with curMem=269194, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.8 MB)
17/10/25 12:51:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:39878 (size: 2.1 KB, free: 530.0 MB)
17/10/25 12:51:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:861
17/10/25 12:51:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at map at Multiply.scala:29)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
17/10/25 12:51:05 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[6] at map at Multiply.scala:28), which has no missing parents
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(3728) called with curMem=271360, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.6 KB, free 529.7 MB)
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(2165) called with curMem=275088, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.1 KB, free 529.7 MB)
17/10/25 12:51:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:39878 (size: 2.1 KB, free: 530.0 MB)
17/10/25 12:51:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:861
17/10/25 12:51:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[6] at map at Multiply.scala:28)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
17/10/25 12:51:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2199 bytes)
17/10/25 12:51:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2199 bytes)
17/10/25 12:51:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/25 12:51:05 INFO Executor: Fetching http://198.202.114.117:41193/jars/multiply.jar with timestamp 1508961062540
17/10/25 12:51:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/10/25 12:51:05 INFO Utils: Fetching http://198.202.114.117:41193/jars/multiply.jar to /tmp/spark-f725472b-5f4a-4f30-83f9-45430b84dd5b/userFiles-1bc52ebe-436a-4ee2-a983-a9aa8e2638e7/fetchFileTemp6163227054908642182.tmp
17/10/25 12:51:05 INFO Executor: Adding file:/tmp/spark-f725472b-5f4a-4f30-83f9-45430b84dd5b/userFiles-1bc52ebe-436a-4ee2-a983-a9aa8e2638e7/multiply.jar to class loader
17/10/25 12:51:05 INFO HadoopRDD: Input split: file:/home/sattri/project3/N-matrix-small.txt:0+33
17/10/25 12:51:05 INFO HadoopRDD: Input split: file:/home/sattri/project3/N-matrix-small.txt:33+34
17/10/25 12:51:05 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/10/25 12:51:05 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/10/25 12:51:05 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/10/25 12:51:05 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/10/25 12:51:05 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/10/25 12:51:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2254 bytes result sent to driver
17/10/25 12:51:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2254 bytes result sent to driver
17/10/25 12:51:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 2199 bytes)
17/10/25 12:51:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
17/10/25 12:51:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 2199 bytes)
17/10/25 12:51:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
17/10/25 12:51:05 INFO HadoopRDD: Input split: file:/home/sattri/project3/M-matrix-small.txt:46+46
17/10/25 12:51:05 INFO HadoopRDD: Input split: file:/home/sattri/project3/M-matrix-small.txt:0+46
17/10/25 12:51:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 2254 bytes result sent to driver
17/10/25 12:51:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 2254 bytes result sent to driver
17/10/25 12:51:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 329 ms on localhost (1/2)
17/10/25 12:51:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 54 ms on localhost (1/2)
17/10/25 12:51:05 INFO DAGScheduler: ShuffleMapStage 0 (map at Multiply.scala:29) finished in 0.390 s
17/10/25 12:51:05 INFO DAGScheduler: looking for newly runnable stages
17/10/25 12:51:05 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/10/25 12:51:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/10/25 12:51:05 INFO DAGScheduler: failed: Set()
17/10/25 12:51:05 INFO DAGScheduler: Missing parents for ShuffleMapStage 2: List(ShuffleMapStage 1)
17/10/25 12:51:05 INFO DAGScheduler: Missing parents for ResultStage 3: List(ShuffleMapStage 2)
17/10/25 12:51:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 395 ms on localhost (2/2)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/25 12:51:05 INFO DAGScheduler: ShuffleMapStage 1 (map at Multiply.scala:28) finished in 0.368 s
17/10/25 12:51:05 INFO DAGScheduler: looking for newly runnable stages
17/10/25 12:51:05 INFO DAGScheduler: running: Set()
17/10/25 12:51:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/10/25 12:51:05 INFO DAGScheduler: failed: Set()
17/10/25 12:51:05 INFO DAGScheduler: Missing parents for ShuffleMapStage 2: List()
17/10/25 12:51:05 INFO DAGScheduler: Missing parents for ResultStage 3: List(ShuffleMapStage 2)
17/10/25 12:51:05 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at map at Multiply.scala:30), which is now runnable
17/10/25 12:51:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 89 ms on localhost (2/2)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(3072) called with curMem=277253, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.0 KB, free 529.7 MB)
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(1669) called with curMem=280325, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1669.0 B, free 529.7 MB)
17/10/25 12:51:05 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:39878 (size: 1669.0 B, free: 530.0 MB)
17/10/25 12:51:05 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:861
17/10/25 12:51:05 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at map at Multiply.scala:30)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
17/10/25 12:51:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, PROCESS_LOCAL, 2019 bytes)
17/10/25 12:51:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, PROCESS_LOCAL, 2019 bytes)
17/10/25 12:51:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
17/10/25 12:51:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 12:51:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1375 bytes result sent to driver
17/10/25 12:51:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 87 ms on localhost (1/2)
17/10/25 12:51:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 1375 bytes result sent to driver
17/10/25 12:51:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 94 ms on localhost (2/2)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/25 12:51:05 INFO DAGScheduler: ShuffleMapStage 2 (map at Multiply.scala:30) finished in 0.092 s
17/10/25 12:51:05 INFO DAGScheduler: looking for newly runnable stages
17/10/25 12:51:05 INFO DAGScheduler: running: Set()
17/10/25 12:51:05 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/10/25 12:51:05 INFO DAGScheduler: failed: Set()
17/10/25 12:51:05 INFO DAGScheduler: Missing parents for ResultStage 3: List()
17/10/25 12:51:05 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[13] at map at Multiply.scala:32), which is now runnable
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(2776) called with curMem=281994, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.7 KB, free 529.7 MB)
17/10/25 12:51:05 INFO MemoryStore: ensureFreeSpace(1613) called with curMem=284770, maxMem=555755765
17/10/25 12:51:05 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1613.0 B, free 529.7 MB)
17/10/25 12:51:05 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:39878 (size: 1613.0 B, free: 530.0 MB)
17/10/25 12:51:05 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:861
17/10/25 12:51:05 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[13] at map at Multiply.scala:32)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
17/10/25 12:51:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, PROCESS_LOCAL, 1957 bytes)
17/10/25 12:51:05 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, PROCESS_LOCAL, 1957 bytes)
17/10/25 12:51:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/25 12:51:05 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 12:51:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 12:51:05 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 1552 bytes result sent to driver
17/10/25 12:51:05 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 12 ms on localhost (1/2)
17/10/25 12:51:05 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 1552 bytes result sent to driver
17/10/25 12:51:05 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 19 ms on localhost (2/2)
17/10/25 12:51:05 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/25 12:51:05 INFO DAGScheduler: ResultStage 3 (collect at Multiply.scala:33) finished in 0.023 s
17/10/25 12:51:05 INFO DAGScheduler: Job 0 finished: collect at Multiply.scala:33, took 0.685552 s
(3,1,56.0)
(1,0,45.0)
(3,0,49.0)
(0,1,-43.0)
(1,2,1.0)
(2,1,21.0)
(0,0,7.0)
(1,1,-9.0)
(2,2,-1.0)
(3,2,0.0)
(0,2,1.0)
(2,0,59.0)
17/10/25 12:51:05 INFO SparkUI: Stopped Spark web UI at http://198.202.114.117:4040
17/10/25 12:51:05 INFO DAGScheduler: Stopping DAGScheduler
17/10/25 12:51:05 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 12:51:05 INFO MemoryStore: MemoryStore cleared
17/10/25 12:51:05 INFO BlockManager: BlockManager stopped
17/10/25 12:51:05 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 12:51:05 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 12:51:05 INFO SparkContext: Successfully stopped SparkContext
17/10/25 12:51:05 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/10/25 12:51:05 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/10/25 12:51:05 INFO ShutdownHookManager: Shutdown hook called
17/10/25 12:51:05 INFO ShutdownHookManager: Deleting directory /tmp/spark-f725472b-5f4a-4f30-83f9-45430b84dd5b
